#å¤šæ™ºèƒ½ä½“çŠ¶æ€å…±äº«
from typing import TypedDict, Annotated, Literal, List, Any

from langchain_core.messages import AIMessage
from pydantic import Field

from RAG.adaptive_retrival import AdaptiveRetrieval
from config.llm_config import moon


class AgentState(TypedDict):
    messages: Annotated[List[str], Field(description="å¯¹è¯å†å²")]
    query: Annotated[str, Field(description="å½“å‰é—®é¢˜")]
    query_type: Literal["research", "analysis", "web_search"]  # æŸ¥è¯¢ç±»å‹
    skip_tool: bool
    research_result: dict
    analysis_result: dict
    web_search_result: dict
    final_answer: str
    current_agent:  str
    user_feedback: str
#åˆ›å»ºèŠ‚ç‚¹
def analysis_query(state: AgentState):
    query = state["query"]
    feedback = state.get("user_feedback", "").strip()

    # ğŸ’¡ æ— è®ºæ˜¯å¦æ˜¯è¿­ä»£ï¼Œéƒ½ä½¿ç”¨ç»“æ„åŒ–çš„æŒ‡ä»¤æ¥çº¦æŸæ¨¡å‹
    role_instruction = """
    ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡è°ƒåº¦ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·é—®é¢˜ï¼Œå¹¶ä»ä»¥ä¸‹å·¥å…·ä¸­é€‰æ‹©æœ€åˆé€‚çš„ä¸€ä¸ªã€‚
    ä¸¥ç¦è¾“å‡ºä»»ä½•å…³äºé—®é¢˜çš„å›ç­”ã€å»ºè®®æˆ–æ”»ç•¥ã€‚

    å¯é€‰å·¥å…·ï¼š
    1. research: é€‚åˆæ·±å…¥çš„ç ”ç©¶ã€å­¦æœ¯å®šä¹‰ã€ç™¾ç§‘çŸ¥è¯†ã€‚
    2. analysis: é€‚åˆé€»è¾‘æ¨ç†ã€æ•°å­¦è®¡ç®—ã€å•ä½è½¬æ¢ã€‚
    3. web_search: é€‚åˆå®æ—¶ä¿¡æ¯ã€å¤©æ°”ã€æœ€æ–°æ–°é—»ã€å…·ä½“åœ°ç‚¹æ¨èã€‚
    4. integrate: ä»…åœ¨ä¸éœ€è¦ä»»ä½•å·¥å…·ã€ç›´æ¥æ•´åˆç°æœ‰ä¿¡æ¯æ—¶ä½¿ç”¨ã€‚
    """

    if not feedback or feedback == "åŒæ„":
        prompt_content = f"{role_instruction}\n\nç”¨æˆ·åŸå§‹é—®é¢˜ï¼š{query}\n\nè¯·åªè¾“å‡ºå·¥å…·åç§°ï¼ˆä¾‹å¦‚ï¼šweb_searchï¼‰ã€‚"
    else:
        prompt_content = f"""
        {role_instruction}

        ### ä»»åŠ¡ä¸Šä¸‹æ–‡ ğŸ“‹
        ç”¨æˆ·åŸå§‹é—®é¢˜ï¼š{query}
        ç”¨æˆ·çš„ä¿®æ”¹æ„è§ï¼š{feedback}

        ### è¾“å‡ºè¦æ±‚ ğŸ§ 
        è¯·ç»“åˆåé¦ˆï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›å¤ï¼š
        TOOL: [å·¥å…·åç§°]
        REASON: [ç®€çŸ­ç†ç”±]
        """

    response = moon.invoke(prompt_content)
    raw_output = response.content.strip().lower()
    print(f"LLM åŸå§‹è¾“å‡º: {raw_output}")

    # é˜²å¾¡æ€§æ¸…æ´—é€»è¾‘ä¿æŒä¸å˜
    if "web_search" in raw_output or "web" in raw_output:
        query_type = "web_search"
    elif "research" in raw_output:
        query_type = "research"
    elif "analysis" in raw_output:
        query_type = "analysis"
    else:
        query_type = "integrate"

    print(f"æ ¡å‡†åçš„è·¯ç”±ç›®æ ‡: {query_type}")
    return {"query_type": query_type, "skip_tools": False, "current_agent": "analyzer"}

async def execute_research_agent(state: AgentState, research_agent=None):
    query = state["query"]

    # åˆå§‹åŒ– AdaptiveRetrievalï¼ˆæŒ‡å‘åŒä¸€ä¸ª Chroma åº“ï¼‰
    retriever = AdaptiveRetrieval(vectorstore_path="/root/autodl-tmp/research_vectorstore")

    # æ‰§è¡Œè‡ªé€‚åº”æ£€ç´¢ï¼ˆè‡ªåŠ¨é€‰æ‹©ç­–ç•¥ï¼‰
    retrieved_docs = await retriever.adaptive_retrieve(
        query=query,
        chat_history=[],
        strategy="history_aware"
    )
    print(retrieved_docs)
    # æ„å»ºå›ç­”
    if retrieved_docs:
        context = "\n\n".join([doc["content"] for doc in retrieved_docs])
        sources = [doc["metadata"].get("source", "æœªçŸ¥") for doc in retrieved_docs]
        prompt = (
            f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šç ”ç©¶å‘˜ï¼Œè¯·åŸºäºä»¥ä¸‹å†…éƒ¨èµ„æ–™å‡†ç¡®å›ç­”é—®é¢˜ã€‚\n\n"
            f"èµ„æ–™ï¼š\n{context}\n\n"
            f"é—®é¢˜ï¼š{query}\n\n"
            f"è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼Œä¸è¦ç¼–é€ ã€‚å¦‚æœèµ„æ–™ä¸è¶³ï¼Œè¯·è¯´â€œæ ¹æ®ç°æœ‰èµ„æ–™æ— æ³•ç¡®å®šâ€ã€‚"
        )
    else:
        prompt = f"é—®é¢˜ï¼š{query}\næ ¹æ®å†…éƒ¨çŸ¥è¯†åº“æ— æ³•æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
        sources = []

    # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæœ€ç»ˆå›ç­”
    response = moon.invoke(prompt)
    answer = response.content.strip()

    # è¿”å›ç»“æ„åŒ–ç»“æœ
    structured_response = {
        "answer": answer,
        "sources": sources,
        "retrieved_count": len(retrieved_docs)
    }

    return {
        "research_result": structured_response,
        "current_agent": "researcher"
    }


async def execute_analysis_agent(state: AgentState, analysis_agent):
    result=await analysis_agent.ainvoke({'messages':[{'role':'user','content':state['query']}]})
    return {"analysis_result": result["structured_response"],
            "current_agent": "analyst"}
async def execute_web_search_agent(state: AgentState, web_search_agent):
    result=await web_search_agent.ainvoke({'messages':[{'role':'user','content':state['query']}]})
    structured=result["structured_response"]
    # âœ… å…³é”®ï¼šå°† AgentResponse è½¬ä¸º dict
    if hasattr(structured, "model_dump"):  # Pydantic v2
        web_result = structured.model_dump()
    elif hasattr(structured, "__dict__"):  # dataclass æˆ–æ™®é€šå¯¹è±¡
        web_result = structured.__dict__
    else:
        web_result = {"answer": str(structured)}  # ä¿åº•æ–¹æ¡ˆ
    return {"web_search_result": web_result,
            "current_agent": "web_searcher"}

async def run_web_search_node(state: AgentState, agent: Any) -> dict:
    result = await execute_web_search_agent(state, agent)
    return result  # å¿…é¡»æ˜¯ dictï¼

async def run_research_node(state: AgentState, agent: Any) -> dict:
    result = await execute_research_agent(state, agent)
    return result

async def run_analysis_node(state: AgentState, agent: Any) -> dict:
    result = await execute_analysis_agent(state, agent)
    return result
def integrate_results(state: AgentState):
    print('è¿›å…¥æœ€åå›ç­”æ•´åˆé˜¶æ®µ')

    # è·å–åŸå§‹ç´ æ
    research = state.get("research_result", {}).get("answer", "")
    analysis = state.get("analysis_result", {}).get("answer", "")
    web = state.get("web_search_result", {}).get("answer", "")

    # è·å–ç”¨æˆ·åé¦ˆ
    feedback = state.get("user_feedback", "").strip()

    # ğŸ’¡ æ ¸å¿ƒä¼˜åŒ–ï¼šæ„å»ºå¸¦æœ‰æŒ‡ä»¤ä¼˜å…ˆçº§çš„ä¸Šä¸‹æ–‡
    context = f"ç ”ç©¶æ•°æ®ï¼š{research}\nåˆ†ææ•°æ®ï¼š{analysis}\nå®æ—¶ä¿¡æ¯ï¼š{web}"

    # å¦‚æœæœ‰åé¦ˆä¸”ä¸æ˜¯â€œåŒæ„â€ï¼Œåˆ™æ„å»ºåé¦ˆæŒ‡ä»¤
    instruction = "è¯·æ•´åˆä»¥ä¸Šä¿¡æ¯ï¼Œç»™å‡ºä¸“ä¸šä¸”è¯¦å°½çš„å›ç­”ã€‚"
    if feedback and feedback != "åŒæ„":
        instruction = f"âš ï¸ ç”¨æˆ·å¯¹ä¸Šä¸€æ¬¡å›ç­”ä¸æ»¡æ„ï¼Œæå‡ºäº†ä»¥ä¸‹ä¿®æ”¹æ„è§ï¼šã€{feedback}ã€‘ã€‚è¯·ä¸¥æ ¼æ ¹æ®æ­¤æ„è§ï¼Œç»“åˆèƒŒæ™¯æ•°æ®é‡æ–°æ’°å†™å›ç­”ã€‚"

    final_prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªå…¨èƒ½å‹æŠ¥å‘Šæ•´åˆä¸“å®¶ã€‚

    [èƒŒæ™¯ç´ æ]
    {context}

    [ä»»åŠ¡æŒ‡ä»¤]
    {instruction}

    æ³¨æ„ï¼šå¦‚æœèƒŒæ™¯ç´ æä¸­ç¼ºå°‘ç”¨æˆ·åé¦ˆæ‰€éœ€çš„ä¿¡æ¯ï¼Œè¯·è¯šå®è¯´æ˜ï¼Œä¸è¦è™šæ„æ•°æ®ã€‚
    """

    response = moon.invoke(final_prompt)
    return {"final_answer": response.content, "current_agent": "integrator"}