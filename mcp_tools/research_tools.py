import datetime
import json
from pathlib import Path
from typing import Optional, List
import sys
import os

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from fastmcp import FastMCP

from config.env_utils import ALi_API_KEY

mcp=FastMCP(name="research_server",instructions="æ£€ç´¢æŸ¥è¯¢mcpæœåŠ¡å™¨")
embeddings=DashScopeEmbeddings(model="text-embedding-v4", dashscope_api_key=ALi_API_KEY,)
vectorstore_path = "/data/research_vectorstore"
#è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
file_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))+ vectorstore_path
try:
        vectorstore = FAISS.load_local(file_path, embeddings,allow_dangerous_deserialization=True)
except:
        Path(file_path).mkdir(parents=True, exist_ok=True)
        #åˆ›å»ºå‘é‡åº“ï¼Œè·å–å‘é‡ç»´åº¦
        dummy_embeddings=embeddings.embed_query('åˆå§‹åŒ–å‘é‡åº“')
        dimension=len(dummy_embeddings)
        from faiss import IndexFlatL2

        index = IndexFlatL2(dimension)
        vectorstore = FAISS(
            embedding_function=embeddings,
            index=index,
            index_to_docstore_id={},
            docstore={},
        )
        vectorstore.save_local(file_path)
        metadatas={"last_updated":datetime.datetime.now().isoformat()}
        with open(str(file_path) +"metadata.json", "w", encoding="utf-8") as f:
            json.dump(metadatas, f, ensure_ascii=False, indent=2)
@mcp.tool(name="semantic_search", description="æ ¹æ®è¾“å…¥çš„æŸ¥è¯¢å†…å®¹ï¼Œè¿”å›æœ€ç›¸å…³çš„å†…å®¹")
async def sentence_similarity(query: str,top_k: int = 5) -> list:
    try:
        docs = vectorstore.similarity_search(query, k=top_k)
        results = []
        for i, doc in enumerate(docs):
            metadata = doc.metadata
            source = metadata.get('source', 'æœªçŸ¥æ¥æº')
            date = metadata.get('date', 'æœªçŸ¥æ—¥æœŸ')

            results.append(
                f"ã€ç»“æœ {i + 1}ã€‘\n"
                f"æ¥æº: {source} | æ—¥æœŸ: {date}\n"
                f"å†…å®¹: {doc.page_content[:300]}...\n"
                f"{'-' * 50}"
            )

        return "\n".join(results)
    except Exception as e:
        return [f"æœç´¢å¤±è´¥: {str(e)}"]

@mcp.tool(name="add_to_knowledge_base", description="æ·»åŠ å†…å®¹åˆ°è¯­ä¹‰æœç´¢ä¸­")
async  def add_content(content: str,metadata: dict=None) -> str:
    try:
        if metadata is None:
            metadata={}
        doc=Document(page_content=content, metadata=metadata)
        vectorstore.add_documents(documents=[doc])
        vectorstore.save_local(file_path)
        return "æ·»åŠ æˆåŠŸï¼Œå½“å‰æ€»æ–‡æ¡£æ•°"
    except:
        return "æ·»åŠ å¤±è´¥"


def load_vectorstore_and_metadata():
    """åŠ è½½å…ƒæ•°æ®"""
    # åŠ è½½å…ƒæ•°æ®
    metadata_file = file_path / "metadata.json"
    if metadata_file.exists():
        with open(metadata_file, "r", encoding="utf-8") as f:
            metadata = json.load(f)
    else:
        metadata = {"last_updated": "æœªçŸ¥", "total_documents": 0}

    return  metadata
@mcp.tool(name="list_knowledge_base_stats",description="æŸ¥çœ‹çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯")
def add_to_knowledge_base(
        text: str,
        source: str = "ç”¨æˆ·è¾“å…¥",
        category: str = "general",
        tags: Optional[List[str]] = None
) -> str:
    """
    æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“

    Args:
        text: æ–‡æœ¬å†…å®¹
        source: æ¥æº
        category: åˆ†ç±»
        tags: æ ‡ç­¾åˆ—è¡¨

    Returns:
        æ“ä½œç»“æœ
    """
    global vectorstore
    # å‡†å¤‡å…ƒæ•°æ®
    metadata = {
        "source": source,
        "category": category,
        "tags": tags or [],
        "added_at": datetime.datetime.now().isoformat(),
        "text_length": len(text)
    }

    # åˆ›å»ºæ–‡æ¡£
    doc = Document(
        page_content=text,
        metadata=metadata
    )

    # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
    vectorstore.add_documents([doc])
    vectorstore.save_local(file_path)

    return f"âœ… æˆåŠŸæ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“\n  æ¥æº: {source}\n  åˆ†ç±»: {category}\n  é•¿åº¦: {len(text)} å­—ç¬¦"

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨åŸºäº Qwen Embedding çš„ç ”ç©¶æœåŠ¡å™¨ (FastMCP)")
    print("ğŸ’¡ è¯·ç¡®ä¿å·²è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
    mcp.run()